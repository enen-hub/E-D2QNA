import torch
import argparse
import numpy as np
import sys
import os
import random
from pathlib import Path

# ==========================================
# 1. è·¯å¾„ä¸ç¯å¢ƒè®¾ç½®
# ==========================================
try:
    CURRENT_DIR = Path(__file__).resolve().parent
    PROJECT_ROOT = CURRENT_DIR
    if str(PROJECT_ROOT) not in sys.path:
        sys.path.insert(0, str(PROJECT_ROOT))
except NameError:
    PROJECT_ROOT = Path.cwd()

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from utils.data_loader import readData
from core.DynamicJobGenerator import DynamicJobGenerator
from envs.DynamicDJSSEnv import DynamicDJSSEnv
# æ³¨æ„ï¼šç¡®ä¿è¿™é‡Œå¯¼å…¥çš„æ˜¯ä¿®å¤äº† FiLM Bug çš„ PolicyNet1
from networks.PolicyNet1 import Policy 
from networks.embeddingModel import get_features_of_node, get_adjacent_matrix

# ==========================================
# 2. å®éªŒé…ç½® (å…³é”®å‚æ•°)
# ==========================================
# ğŸ”¥ è¯·æ›¿æ¢ä¸ºä½ ç›®å‰æœ€å¼ºçš„æ¨¡å‹è·¯å¾„ (ä¾‹å¦‚ Ep 186 æˆ– Ep 68)
MODEL_PATH = r"result/E_D2QNA/capture_best/best_model.pth" 

JSON_PATH = "dataset/la16/la16_K1.3.json"
EPISODES = 20           # æµ‹è¯• 20 è½®å–å¹³å‡
JOBS_PER_EP = 50        # æ¯è½® 50 ä¸ªå·¥ä»¶
FAILURE_PROB = 0.05     # ğŸ”¥ æ•…éšœæ¦‚ç‡ï¼šæ¯æ­¥æœ‰ 5% æ¦‚ç‡å‘ç”Ÿæœºå™¨æ•…éšœ
REPAIR_TIME = 50.0      # ğŸ”¥ æ•…éšœä»£ä»·ï¼šæœºå™¨éœ€è¦ä¿® 50 ä¸ªæ—¶é—´å•ä½ (å¡é¡¿)

# ç»“æœè¾“å‡ºç›®å½•
OUTPUT_DIR = PROJECT_ROOT / "result" / "robustness_test"

# DRL é…ç½® (éœ€ä¸è®­ç»ƒæ—¶ä¸€è‡´)
CONFIG = {
    "model": {
        "raw_feat_dim": 11,   # V5 ç‰ˆæœ¬é€šå¸¸æ˜¯ 11
        "num_actions": 7,
        "embed_dim": 32,
        "gcn_hidden": 256,
        "num_heads": 8,
        "lstm_hidden": 128,
        "num_objectives": 2
    },
    "action_space": {"num_rules": 7},
    "objectives_config": {"active_objectives": ["tardiness", "flow_time"]}
}

ACTION_LIST = ['SPT', 'LPT', 'SR', 'LR', 'FOPNR', 'MORPNR', 'RANDOM']

def load_policy(device):
    """åŠ è½½è®­ç»ƒå¥½çš„ DRL æ¨¡å‹"""
    if not os.path.exists(MODEL_PATH):
        print(f"âŒ Error: Model file not found at {MODEL_PATH}")
        sys.exit(1)
        
    print(f"ğŸ”„ Loading Model: {MODEL_PATH}")
    policy = Policy(CONFIG, device=str(device))
    
    # åŠ è½½æƒé‡
    try:
        checkpoint = torch.load(MODEL_PATH, map_location=device)
        state_dict = checkpoint.get('model_state_dict', checkpoint)
        # å…¼å®¹æ€§å¤„ç†ï¼šå»é™¤ module. å‰ç¼€
        new_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
        policy.load_state_dict(new_state_dict, strict=False)
        print("âœ… Model loaded successfully!")
    except Exception as e:
        print(f"âš ï¸ Model load warning: {e}")
        
    policy.eval()
    return policy

def inject_machine_failure(env):
    """æ¨¡æ‹Ÿæœºå™¨æ•…éšœï¼šéšæœºæŒ‘é€‰ä¸€å°æœºå™¨ï¼Œå¢åŠ å…¶å®Œæˆæ—¶é—´ï¼ˆæ¨¡æ‹Ÿè¢«å¡ä½ï¼‰"""
    if random.random() < FAILURE_PROB:
        victim = random.choice(env.machines)
        # æƒ©ç½šï¼šè®©è¿™å°æœºå™¨çš„å½“å‰æ—¶é—´å¼ºè¡Œæ¨åï¼Œæ¨¡æ‹Ÿç»´ä¿®è€—æ—¶
        victim.currentTime += REPAIR_TIME
        return True
    return False

def run_robustness_test():
    # è®¾å¤‡é€‰æ‹©
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ Starting Robustness Test on {device}")
    print(f"âš™ï¸  Conditions: Failure Prob={FAILURE_PROB*100}%, Repair Time={REPAIR_TIME}")
    
    # 1. å‡†å¤‡æ•°æ®
    _, jobs_tmpl, machines_tmpl = readData(JSON_PATH, validate=False)
    policy = load_policy(device)
    
    # 2. åå¥½å‘é‡ (ä¸“æ³¨ Tardiness)
    w_eval = torch.tensor([1.0, 0.0], dtype=torch.float32, device=device).view(1, -1)
    
    # ç»“æœæ”¶é›†
    results = {"SPT": [], "DRL": [], "FAIL_SPT": [], "FAIL_DRL": []}
    
    print(f"\n{'Ep':<5} {'SPT Tard':<12} {'DRL Tard':<12} {'Gap (%)':<10} {'Failures':<8}")
    print("-" * 60)
    
    for ep in range(EPISODES):
        seed = 999 + ep # å›ºå®šç§å­åºåˆ—
        
        # -------------------------------------------------
        # Round 1: SPT (Industry Baseline)
        # -------------------------------------------------
        job_gen_spt = DynamicJobGenerator(jobs_tmpl, config={"seed": seed, "urgent_prob": 0.3})
        env_spt = DynamicDJSSEnv(job_gen_spt, machines_tmpl, device)
        
        g = env_spt.reset(num_dynamic_jobs=JOBS_PER_EP)
        done = False
        fail_count_spt = 0
        
        while not done:
            if g is None: 
                g, _, done = env_spt.step("RANDOM", multi_objective=True)
                continue
                
            # ğŸ”¥ æ³¨å…¥æ•…éšœ
            if inject_machine_failure(env_spt): fail_count_spt += 1
            
            # SPT å†³ç­–
            g, _, done = env_spt.step("SPT", multi_objective=True)
            
        spt_tardiness = env_spt.total_tardiness / JOBS_PER_EP
        
        # -------------------------------------------------
        # Round 2: DRL (Ours)
        # -------------------------------------------------
        # å…³é”®ï¼šä½¿ç”¨ç›¸åŒçš„ Seed é‡ç½®ç¯å¢ƒï¼Œä¿è¯å·¥ä»¶åˆ°è¾¾åºåˆ—å®Œå…¨ä¸€è‡´
        # ä½†æ•…éšœæ˜¯éšæœºæ³¨å…¥çš„ï¼Œè¿™ç¬¦åˆçœŸå®ä¸–ç•Œçš„â€œä¸å¯é¢„æµ‹æ€§â€
        job_gen_drl = DynamicJobGenerator(jobs_tmpl, config={"seed": seed, "urgent_prob": 0.3})
        env_drl = DynamicDJSSEnv(job_gen_drl, machines_tmpl, device)
        
        g = env_drl.reset(num_dynamic_jobs=JOBS_PER_EP)
        h_state = policy.init_hidden_state(1)
        done = False
        fail_count_drl = 0
        
        while not done:
            if g is None: 
                g, _, done = env_drl.step("RANDOM", multi_objective=True)
                continue
            
            # ğŸ”¥ æ³¨å…¥æ•…éšœ (éšæœºæ€§ç‹¬ç«‹ï¼Œæ¨¡æ‹ŸçœŸå®æŒ‘æˆ˜)
            # ä¸ºäº†å…¬å¹³å¯¹æ¯”ï¼Œä½ å¯ä»¥å›ºå®šæ•…éšœç§å­ï¼Œä½†åœ¨é²æ£’æ€§æµ‹è¯•ä¸­ï¼Œéšæœºæ€§æ›´èƒ½ä½“ç°æ³›åŒ–èƒ½åŠ›
            if inject_machine_failure(env_drl): fail_count_drl += 1
            
            # DRL å†³ç­–
            feats = get_features_of_node(g, env_drl.machines, device=device)
            adj = get_adjacent_matrix(g, device=device)
            ei = adj.to_sparse().indices()
            idx = torch.zeros(feats.size(0), dtype=torch.long, device=device)
            
            with torch.no_grad():
                q, h_state = policy(feats, ei, h_state, batch=idx, w=w_eval)
                # æ˜¾å¼é€‰æ‹© Tardiness ç»´åº¦ (ç´¢å¼•0) æœ€å¤§çš„åŠ¨ä½œ
                score = (q * w_eval.view(1,1,-1)).sum(dim=2)
                action = score.argmax().item()
                rule = ACTION_LIST[action]
            
            g, _, done = env_drl.step(rule, multi_objective=True)
            
        drl_tardiness = env_drl.total_tardiness / JOBS_PER_EP
        
        # è®°å½•ç»“æœ
        results["SPT"].append(spt_tardiness)
        results["DRL"].append(drl_tardiness)
        results["FAIL_SPT"].append(fail_count_spt)
        results["FAIL_DRL"].append(fail_count_drl)
        
        gap = (spt_tardiness - drl_tardiness) / (spt_tardiness + 1e-5) * 100
        print(f"{ep+1:<5} {spt_tardiness:<12.1f} {drl_tardiness:<12.1f} {gap:<+10.1f} {fail_count_drl:<8}")

    # ==========================================
    # 3. æœ€ç»ˆç»Ÿè®¡
    # ==========================================
    avg_spt = np.mean(results["SPT"])
    avg_drl = np.mean(results["DRL"])
    final_gap = (avg_spt - avg_drl) / avg_spt * 100
    
    print("\n" + "="*60)
    print("ğŸ† FINAL ROBUSTNESS REPORT")
    print("="*60)
    print(f"Simulation: {EPISODES} episodes with {FAILURE_PROB*100}% machine failure rate.")
    print(f"SPT Avg Tardiness : {avg_spt:.2f}")
    print(f"DRL Avg Tardiness : {avg_drl:.2f}")
    print("-" * 30)
    
    if final_gap > 0:
        print(f"ğŸ‰ VICTORY: DRL outperforms SPT by {final_gap:.2f}% under uncertainty!")
        print("ğŸ’¡ Narrative: 'While SPT is brittle to disruptions, E-D2QNA maintains stability.'")
    else:
        print(f"âš ï¸ RESULT: DRL lags by {-final_gap:.2f}%. Try increasing failure repair time?")
    print("="*60)

    # ==========================================
    # 4. ä¿å­˜ç»“æœåˆ°æŒ‡å®šç›®å½•
    # ==========================================
    try:
        OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

        # æŒ‰æ¨¡å‹åˆ†ç›®å½•ä¿å­˜æ¯è½®ç»“æœ
        model_stem = Path(MODEL_PATH).stem
        out_dir_model = OUTPUT_DIR / model_stem
        out_dir_model.mkdir(parents=True, exist_ok=True)

        episodic_csv = out_dir_model / "episodic_results.csv"
        with open(episodic_csv, "w", encoding="utf-8") as f:
            f.write("episode,spt_tardiness,drl_tardiness,gap_percent,fail_spt,fail_drl\n")
            for i, (spt, drl, fs, fd) in enumerate(zip(results["SPT"], results["DRL"], results["FAIL_SPT"], results["FAIL_DRL"])):
                gap_i = (spt - drl) / (spt + 1e-5) * 100
                f.write(f"{i+1},{spt:.2f},{drl:.2f},{gap_i:.2f},{fs},{fd}\n")

        # æ±‡æ€»ç»“æœï¼ˆè¿½åŠ æ¨¡å¼ï¼‰
        summary_csv = OUTPUT_DIR / "summary.csv"
        write_header = not summary_csv.exists()
        with open(summary_csv, "a", encoding="utf-8") as f:
            if write_header:
                f.write("model,episodes,jobs_per_ep,failure_prob,repair_time,avg_spt,avg_drl,final_gap\n")
            f.write(
                f"{Path(MODEL_PATH).name},{EPISODES},{JOBS_PER_EP},{FAILURE_PROB},{REPAIR_TIME},{avg_spt:.2f},{avg_drl:.2f},{final_gap:.2f}\n"
            )

        print(f"ğŸ“ Results saved: {OUTPUT_DIR}")
        print(f"   - {model_stem}\\episodic_results.csv")
        print(f"   - summary.csv (appended)")
    except Exception as e:
        print(f"âš ï¸ Failed to save results to {OUTPUT_DIR}: {e}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Robustness test runner")
    parser.add_argument("--model_path", type=str, default="", help="Path to checkpoint .pth")
    parser.add_argument("--episodes", type=int, default=EPISODES)
    parser.add_argument("--jobs_per_ep", type=int, default=JOBS_PER_EP)
    parser.add_argument("--failure_prob", type=float, default=FAILURE_PROB)
    parser.add_argument("--repair_time", type=float, default=REPAIR_TIME)
    args = parser.parse_args()

    if args.model_path:
        MODEL_PATH = args.model_path
    EPISODES = args.episodes
    JOBS_PER_EP = args.jobs_per_ep
    FAILURE_PROB = args.failure_prob
    REPAIR_TIME = args.repair_time

    run_robustness_test()
